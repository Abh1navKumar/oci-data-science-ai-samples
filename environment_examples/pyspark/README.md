PySpark and Data Flow 
=====================

The PySpark and Data Flow conda allows you to leverage the power of Apache Spark. Use it to access the full computational power of a notebook session by using parallel computing. For larger jobs, you can interactively develop Spark applications and submit them to Oracle Data Flow without blocking the notebook session. PySpark MLlib implements a wide collection of powerful machine-learning algorithms. Use the SQL-like language of PySparkSQL to analyze huge amounts of structure and semi-structured data stored on Oracle Object Storage. Speed up your workflow by using sparksql-magic to run PySparkSQL queries directly in the notebook.


The notebooks in this folder are meant to be run in our PySpark conda pack.


## License

Copyright (c) 2021 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at <https://oss.oracle.com/licenses/upl/>.
