{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Pytorch training using Horovod via OCI Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "1. [Train](#Train)\n",
    "1. [Setup IAM](#Setup%20IAM)\n",
    "1. [Build](#Build)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and MXNet. This notebook example shows how to use Horovod with Tensorflow in OCI Data Science Jobs .\n",
    "\n",
    "For more information about the Horovod with TensorFlow , please visit [Horovod-Tensorflow](https://horovod.readthedocs.io/en/stable/tensorflow.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install ads package >= 2.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install docker:\n",
    "\n",
    "https://docs.docker.com/get-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "A sample training script 'sample.py' which will be used as by different workers in the setup for distributeed training\n",
    "\n",
    "This script uses Horovod framework for distributed training where Horovod-related lines are commented starting with `Horovod:`. For example, `Horovod: add Horovod DistributedOptimizer`, `Horovod: initialize optimize` and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sample.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from filelock import FileLock\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data.distributed\n",
    "import horovod.torch as hvd\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--fp16-allreduce', action='store_true', default=False,\n",
    "                    help='use fp16 compression during allreduce')\n",
    "parser.add_argument('--use-adasum', action='store_true', default=False,\n",
    "                    help='use adasum algorithm to do reduction')\n",
    "parser.add_argument('--data-dir',\n",
    "                    help='location of the training dataset in the local filesystem (will be downloaded if needed)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# Horovod: initialize library.\n",
    "hvd.init()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.cuda:\n",
    "    # Horovod: pin GPU to local rank.\n",
    "    torch.cuda.set_device(hvd.local_rank())\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "# Horovod: limit # of CPU threads to be used per worker.\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "data_dir = args.data_dir or './data'\n",
    "with FileLock(os.path.expanduser(\"~/.horovod_lock\")):\n",
    "    train_dataset = \\\n",
    "        datasets.MNIST(data_dir, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "# Horovod: use DistributedSampler to partition the training data.\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\n",
    "\n",
    "test_dataset = \\\n",
    "    datasets.MNIST(data_dir, train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "# Horovod: use DistributedSampler to partition the test data.\n",
    "test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    test_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\n",
    "                                          sampler=test_sampler, **kwargs)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# By default, Adasum doesn't need scaling up learning rate.\n",
    "lr_scaler = hvd.size() if not args.use_adasum else 1\n",
    "\n",
    "if args.cuda:\n",
    "    # Move model to GPU.\n",
    "    model.cuda()\n",
    "    # If using GPU Adasum allreduce, scale learning rate by local_size.\n",
    "    if args.use_adasum and hvd.nccl_built():\n",
    "        lr_scaler = hvd.local_size()\n",
    "\n",
    "# Horovod: scale learning rate by lr_scaler.\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr * lr_scaler,\n",
    "                      momentum=args.momentum)\n",
    "\n",
    "# Horovod: (optional) compression algorithm.\n",
    "compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n",
    "\n",
    "\n",
    "def metric_average(val, name):\n",
    "    tensor = torch.tensor(val)\n",
    "    avg_tensor = hvd.allreduce(tensor, name=name)\n",
    "    return avg_tensor.item()\n",
    "\n",
    "\n",
    "@hvd.elastic.run\n",
    "def train(state):\n",
    "    # post synchronization event (worker added, worker removed) init ...\n",
    "    for state.epoch in range(state.epoch, args.epochs + 1):\n",
    "        state.model.train()\n",
    "\n",
    "        train_sampler.set_epoch(state.epoch)\n",
    "        steps_remaining = len(train_loader) - state.batch\n",
    "\n",
    "        for state.batch, (data, target) in enumerate(train_loader):\n",
    "            if state.batch >= steps_remaining:\n",
    "                break\n",
    "\n",
    "            if args.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            state.optimizer.zero_grad()\n",
    "            output = state.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            state.optimizer.step()\n",
    "            if state.batch % args.log_interval == 0:\n",
    "                # Horovod: use train_sampler to determine the number of examples in\n",
    "                # this worker's partition.\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    state.epoch, state.batch * len(data), len(train_sampler),\n",
    "                    100.0 * state.batch / len(train_loader), loss.item()))\n",
    "            state.commit()\n",
    "        state.batch = 0\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_accuracy = 0.\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n",
    "\n",
    "    # Horovod: use test_sampler to determine the number of examples in\n",
    "    # this worker's partition.\n",
    "    test_loss /= len(test_sampler)\n",
    "    test_accuracy /= len(test_sampler)\n",
    "\n",
    "    # Horovod: average metric values across workers.\n",
    "    test_loss = metric_average(test_loss, 'avg_loss')\n",
    "    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\n",
    "\n",
    "    # Horovod: print output only on first rank.\n",
    "    if hvd.rank() == 0:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
    "            test_loss, 100. * test_accuracy))\n",
    "\n",
    "\n",
    "# Horovod: wrap optimizer with DistributedOptimizer.\n",
    "optimizer = hvd.DistributedOptimizer(optimizer,\n",
    "                                     named_parameters=model.named_parameters(),\n",
    "                                     compression=compression,\n",
    "                                     op=hvd.Adasum if args.use_adasum else hvd.Average)\n",
    "\n",
    "\n",
    "# adjust learning rate on reset\n",
    "def on_state_reset():\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = args.lr * hvd.size()\n",
    "\n",
    "\n",
    "state = hvd.elastic.TorchState(model, optimizer, epoch=1, batch=0)\n",
    "state.register_reset_callbacks([on_state_reset])\n",
    "train(state)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup IAM\n",
    "\n",
    "### Create the Dynamic Group\n",
    "```\n",
    "ALL {resource.type = ‘datasciencejobrun’, resource.compartment.id = <COMPARTMENT_OCID>}\n",
    "```\n",
    "\n",
    "### Create the following Policy\n",
    "```\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to use log-content in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to use log-groups in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to inspect repos in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to inspect vcns in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to manage objects in compartment <COMPARTMENT_NAME> where any {target.bucket.name=<BUCKET_NAME>}\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to manage buckets in compartment <COMPARTMENT_NAME> where any {target.bucket.name='BUCKET_NAME'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build\n",
    "\n",
    "### Initialize a distributed-training folder\n",
    "By this time, you would have created a training file (or files) - sample.py from the above example. Now running the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ads opctl distributed-training init --framework horovod --version v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Docker image\n",
    "\n",
    "The sample code is assumed to be in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -f oci_dist_training_artifacts/horovod/docker/pytorch.cpu.Dockerfile -t (IMAGE-NAME):(TAG) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the Docker Image to OCIR\n",
    "\n",
    "#### Steps\n",
    "1. Follow the instructions to setup container registry from [here](https://docs.oracle.com/en-us/iaas/Content/Registry/Tasks/registrypushingimagesusingthedockercli.htm)\n",
    "2. Make sure you create a repository in OCIR to push the image\n",
    "3. Tag Local Docker image that needs to be pushed -> `docker tag \"image-identifier\" \"target-tag\"`\n",
    "4. Push the Docker image from the client machine to Container Registry -> `docker push \"target-tag\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tag Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag hvdjob-cpu-pytorch-1.0 iad.ocir.io/<TENANCY_NAME>/horovod:hvdjob-cpu-pytorch-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Push Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push iad.ocir.io/<TENANCY_NAME>/horovod:hvdjob-cpu-pytorch-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your workload yaml:\n",
    "\n",
    "The yaml file is a declarative way to express the workload.\n",
    "Edit the `\"oci_dist_training_artifacts/horovod/jobrun_config/jobrun_config_hvd_tf.yaml\"` file to specify run config\n",
    "\n",
    "The following variables are tenancy specific that needs to be modified\n",
    "\n",
    "| Variable | Description |\n",
    "| :-------- | :----------- |\n",
    "|compartmentId|OCID of the compartment where Data Science projects are created|\n",
    "|projectId|OCID of the project created in Data Science service|\n",
    "|subnetId|OCID of the subnet attached your Job|\n",
    "|logGroupId|OCID of the log group for JobRun logs|\n",
    "|image|Image from OCIR to be used for JobRuns|\n",
    "|workDir|URL to the working directory for opctl|\n",
    "|WORKSPACE|Workspace with the working directory to be used|\n",
    "|entryPoint|The script to be executed when launching the container|\n",
    "\n",
    "```yaml\n",
    "kind: distributed\n",
    "apiVersion: v1.0\n",
    "spec:\n",
    "  infrastructure: # This section maps to Job definition. Does not include environment variables\n",
    "    kind: infrastructure\n",
    "    type: dataScienceJob\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      projectId: <PROJECT_OCID>\n",
    "      compartmentId: <COMPARTMENT_OCID>\n",
    "      displayName: <DISPLAY_NAME>\n",
    "      logGroupId: <LOG_GROUP_OCID>\n",
    "      subnetId: <SUBNET_OCID>\n",
    "      shapeName: <COMPUTE_SHAPE>\n",
    "      blockStorageSize: <SIZE_IN_GB>\n",
    "      blockStorageSizeInGBs: <SIZE_IN_GB>\n",
    "  cluster:\n",
    "    kind: HOROVOD\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      image: \"<REGION_CODE>.ocir.io/<TENANCY_NAME>/<REPOSITORY_NAME>:<IMAGE_TAG>\"\n",
    "      workDir:  \"oci://<BUCKET_NAME>@<NAMESPACE>/\"\n",
    "      name: \"<DISPLAY_NAME>\"\n",
    "      config:\n",
    "        env:\n",
    "          - name: MIN_NP\n",
    "            value: 2\n",
    "          - name: MAX_NP\n",
    "            value: 8\n",
    "          - name: SLOTS\n",
    "            value: 2\n",
    "          - name: WORKER_PORT\n",
    "            value: 12345\n",
    "          - name: GLOO_TIMEOUT_SECONDS\n",
    "            value: 90\n",
    "          - name: START_TIMEOUT\n",
    "            value: 700\n",
    "          - name: ENABLE_TIMELINE\n",
    "            value: 1\n",
    "          - name: SYNC_ARTIFACTS\n",
    "            value: 1\n",
    "          - name: WORKSPACE\n",
    "            value: \"horovod-ws\"\n",
    "          - name: WORKSPACE_PREFIX\n",
    "            value: \"hvd\"\n",
    "      main:\n",
    "        name: \"scheduler\"\n",
    "        replicas: 1\n",
    "      worker:\n",
    "        name: \"worker\"\n",
    "        replicas: 2\n",
    "  runtime:\n",
    "    kind: python\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      entryPoint: \"/code/sample.py\"\n",
    "      args: \"\"\n",
    "      kwargs: \"\"\n",
    "      env:\n",
    "        - name: ARTIFACTS_DIR\n",
    "          value: \"/opt/ml\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "notice": "Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
