{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08ce7ea8",
   "metadata": {},
   "source": [
    "qweews@notebook{feature_store-querying.ipynb,\n",
    "    title: Using feature store for synthetic data generation using openai,\n",
    "    summary: Feature store quickstart guide to perform synthetic data generation using openai,\n",
    "    developed_on: pyspark32_p38_cpu_feature_store_v1,\n",
    "    keywords: feature store, querying, synthetic data generation\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540a608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T08:26:08.572567Z",
     "start_time": "2023-05-24T08:26:08.328013Z"
    }
   },
   "outputs": [],
   "source": [
    "!odsc conda install -s fspyspark32_p38_cpu_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9091f",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "***\n",
    "\n",
    "# <font color=\"red\">Synthetic data generation in feature store using OpenAI and FewShotPromptTemplate</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "---\n",
    "# Overview:\n",
    "---\n",
    "Synthetic data is artificially generated data, rather than data collected from real-world events. It's used to simulate real data without compromising privacy or encountering real-world limitations. \n",
    "\n",
    "Benefits of Synthetic Data:\n",
    "\n",
    "1. **Privacy and Security**: No real personal data at risk of breaches.\n",
    "2. **Data Augmentation**: Expands datasets for machine learning.\n",
    "3. **Flexibility**: Create specific or rare scenarios.\n",
    "4. **Cost-effective**: Often cheaper than real-world data collection.\n",
    "5. **Regulatory Compliance**: Helps navigate strict data protection laws.\n",
    "6. **Model Robustness**: Can lead to better generalizing AI models.\n",
    "7. **Rapid Prototyping**: Enables quick testing without real data.\n",
    "8. **Controlled Experimentation**: Simulate specific conditions.\n",
    "9. **Access to Data**: Alternative when real data isn't available.\n",
    "\n",
    "Note: Despite the benefits, synthetic data should be used carefully, as it may not always capture real-world complexities.\n",
    "\n",
    "\n",
    "Compatible conda pack: [PySpark 3.2 and Feature store](https://docs.oracle.com/iaas/data-science/using/conda-pyspark-fam.htm) for CPU on Python 3.8\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href=\"#concepts\">1. Introduction</a>\n",
    "- <a href='#pre-requisites'>1. Pre-requisites</a>\n",
    "    - <a href='#policies'>2.1 Policies</a>\n",
    "    - <a href='#prerequisites_authentication'>2.2 Authentication</a>\n",
    "    - <a href='#prerequisites_variables'>2.3 Variables</a>\n",
    "- <a href='#featurestore_querying'>3. Feature store querying</a>\n",
    "    - <a href='#data_exploration'>3.1. Exploration of data in feature store</a>\n",
    "    - <a href='#load_featuregroup'>3.2. Load feature groups</a>\n",
    "    - <a href='#explore_featuregroup'>3.3. Explore feature groups</a>\n",
    "    - <a href='#select_subset_featuregroup'>3.4. Select subset of features</a>\n",
    "    - <a href='#filter_featuregroup'>3.5. Filter feature groups</a>\n",
    "    - <a href='#join_featuregroup'>3.6. Apply joins on feature group</a>\n",
    "    - <a href='#create_dataset'>3.7. Create dataset from multiple or one feature group</a>\n",
    "    - <a href='#sql_query'>3.8 Free form sql query</a>\n",
    "- <a href='#ref'>4. References</a>\n",
    "\n",
    "---\n",
    "\n",
    "**Important:**\n",
    "\n",
    "Placeholder text for required values are surrounded by angle brackets that must be removed when adding the indicated content. For example, when adding a database name to `database_name = \"<database_name>\"` would become `database_name = \"production\"`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccad82e",
   "metadata": {},
   "source": [
    "<a id=\"concepts\"></a>\n",
    "# 1. Introduction\n",
    "\n",
    "Oracle feature store is a stack based solution that is deployed in the customer enclave using OCI resource manager. Customer can stand up the service with infrastructure in their own tenancy. The service consists of API which are deployed in customer tenancy using resource manager.\n",
    "\n",
    "The following are some key terms that will help you understand OCI Data Science Feature Store:\n",
    "\n",
    "\n",
    "* **Feature Vector**: Set of feature values for any one primary/identifier key. Eg. All/subset of features of customer id ‘2536’ can be called as one feature vector.\n",
    "\n",
    "* **Feature**: A feature is an individual measurable property or characteristic of a phenomenon being observed.\n",
    "\n",
    "* **Entity**: An entity is a group of semantically related features. The first step a consumer of features would typically do when accessing the feature store service is to list the entities and the entities associated features. Another way to look at it is that an entity is an object or concept that is described by its features. Examples of entities could be customer, product, transaction, review, image, document, etc.\n",
    "\n",
    "* **Feature Group**: A feature group in a feature store is a collection of related features that are often used together in ml models. It serves as an organizational unit within the feature store for users to manage, version and share features across different ml projects. By organizing features into groups, data scientists and ml engineers can efficiently discover, reuse and collaborate on features reducing the redundant work and ensuring consistency in feature engineering.\n",
    "\n",
    "* **Feature Group Job**: Feature group job is the execution instance of a feature group. Each feature group job will include validation results and statistics results.\n",
    "\n",
    "* **Dataset**: A dataset is a collection of feature that are used together to either train a model or perform model inference.\n",
    "\n",
    "* **Dataset Job**: Dataset job is the execution instance of a dataset. Each dataset job will include validation results and statistics results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10112d75",
   "metadata": {},
   "source": [
    "<a id='pre-requisites'></a>\n",
    "# 2. Pre-requisites\n",
    "\n",
    "Data Flow Sessions are accessible through the following conda environment:\n",
    "\n",
    "* **PySpark 3.2, Feature store 1.0 and Data Flow 1.0 (fs_pyspark32_p38_cpu_v1)**\n",
    "\n",
    "The [Data Catalog Hive Metastore](https://docs.oracle.com/en-us/iaas/data-catalog/using/metastore.htm) provides schema definitions for objects in structured and unstructured data assets. The Metastore is the central metadata repository to understand tables backed by files on object storage. You can customize `fs_pyspark32_p38_cpu_v1`, publish it, and use it as a runtime environment for a Data Flow session cluster. The metastore id of hive metastore is tied to feature store construct of feature store service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5d150",
   "metadata": {},
   "source": [
    "<a id='setup_spark-defaults'></a>\n",
    "### `spark-defaults.conf`\n",
    "\n",
    "The `spark-defaults.conf` file is used to define the properties that are used by Spark. A templated version is installed when you install a Data Science conda environment that supports PySpark. However, you must update the template so that the Data Catalog metastore can be accessed. You can do this manually. However, the `odsc data-catalog config` commandline tool is ideal for setting up the file because it gathers information about your environment, and uses that to build the file.\n",
    "\n",
    "The `odsc data-catalog config` command line tool needs the `--metastore` option to define the Data Catalog metastore OCID. No other command line option is needed because settings have default values, or they take values from your notebook session environment. Following are common parameters that you may need to override.\n",
    "\n",
    "The `--authentication` option sets the authentication mode. It supports resource principal and API keys. The preferred method for authentication is resource principal, which is sent with `--authentication resource_principal`. If you want to use API keys, then use the `--authentication api_key` option. If the `--authentication` isn't specified, API keys are used. When API keys are used, information from the OCI configuration file is used to create the `spark-defaults.conf` file.\n",
    "\n",
    "Object Storage and Data Catalog are regional services. By default, the region is set to the region your notebook session is running in. This information is taken from the environment variable, `NB_REGION`. Use the `--region` option to override this behavior.\n",
    "\n",
    "The default location of the `spark-defaults.conf` file is `/home/datascience/spark_conf_dir` as defined in the `SPARK_CONF_DIR` environment variable. Use the `--output` option to define the directory where to write the file.\n",
    "\n",
    "You need to determine what settings are appropriate for your configuration. However, the following works for most configurations and is run in a terminal window.\n",
    "\n",
    "```bash\n",
    "odsc data-catalog config --authentication resource_principal --metastore <metastore_id>\n",
    "```\n",
    "For more assistance, use the following command in a terminal window:\n",
    "\n",
    "```bash\n",
    "odsc data-catalog config --help\n",
    "```\n",
    "\n",
    "<a id='setup_session'></a>\n",
    "### Session Setup\n",
    "\n",
    "The notebook makes connections to the Data Catalog metastore and Object Storage. In the next cell, specify the bucket URI to act as the data warehouse. Use the `warehouse_uri` variable with the `oci://<bucket_name>@<namespace_name>/<key>` format. Update the variable `metastore_id` with the OCID of the Data Catalog metastore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cf08c",
   "metadata": {},
   "source": [
    "python -m pip install --pre oracle-ads==2.9.0rc0<a id='policies'></a>\n",
    "### 2.1. Policies\n",
    "This section covers the creation of dynamic groups and policies needed to use the service.\n",
    "\n",
    "* [Data Flow Policies](https://docs.oracle.com/iaas/data-flow/using/policies.htm/)\n",
    "* [Data Catalog Metastore Required Policies](https://docs.oracle.com/en-us/iaas/data-catalog/using/metastore.htm)\n",
    "* [Getting Started with Data Flow](https://docs.oracle.com/iaas/data-flow/using/dfs_getting_started.htm)\n",
    "* [About Data Science Policies](https://docs.oracle.com/iaas/data-science/using/policies.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58254d54",
   "metadata": {},
   "source": [
    "<a id=\"prerequisites_authentication\"></a>\n",
    "### 2.2. Authentication\n",
    "The [Oracle Accelerated Data Science SDK (ADS)](https://docs.oracle.com/iaas/tools/ads-sdk/latest/index.html) controls the authentication mechanism with the notebook cluster.<br>\n",
    "To setup authentication use the ```ads.set_auth(\"resource_principal\")``` or ```ads.set_auth(\"api_key\")```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba4645b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-24T08:26:08.577504Z"
    },
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(auth=\"resource_principal\", client_kwargs={\"fs_service_endpoint\": \"https://{api_gateway}/20230101\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc59b8",
   "metadata": {},
   "source": [
    "<a id=\"prerequisites_variables\"></a>\n",
    "### 2.3. Variables\n",
    "To run this notebook, you must provide some information about your tenancy configuration. To create and run a feature store, you must specify a `<compartment_id>` and bucket `<metastore_id>` for offline feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2e6e30",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\")\n",
    "metastore_id = \"<metastore_id>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5134a",
   "metadata": {},
   "source": [
    "<a id=\"featurestore_querying\"></a>\n",
    "# 3. Feature group use cases\n",
    "By default the **PySpark 3.2, Feature store and Data Flow** conda environment includes pre-installed [great-expectations](https://legacy.docs.greatexpectations.io/en/latest/reference/core_concepts/validation.html) and [deeque](https://github.com/awslabs/deequ) libraries. The joining functionality is heavily inspired by the APIs used by Pandas to merge, join or filter DataFrames. The APIs allow you to specify which features to select from which feature group, how to join them and which features to use in join conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d90d07",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"iteritems is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67bfc0f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/ads/model/deployment/model_deployment.py:54: DeprecationWarning: The `ads.model.deployment.model_deployment_properties` is deprecated in `oracle-ads 2.8.6` and will be removed in `oracle-ads 3.0`.Use `ModelDeploymentInfrastructure` and `ModelDeploymentRuntime` classes in `ads.model.deployment` module for configuring model deployment. Check https://accelerated-data-science.readthedocs.io/en/latest/user_guide/model_registration/introduction.html\n",
      "  from .model_deployment_properties import ModelDeploymentProperties\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/ads/model/deployment/__init__.py:7: DeprecationWarning: The `ads.model.deployment.model_deployer` is deprecated in `oracle-ads 2.8.6` and will be removed in `oracle-ads 3.0`.Use `ModelDeployment` class in `ads.model.deployment` module for initializing and deploying model deployment. Check https://accelerated-data-science.readthedocs.io/en/latest/user_guide/model_registration/introduction.html\n",
      "  from .model_deployer import ModelDeployer\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:35: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pyarrow.__version__) < LooseVersion(minimum_pyarrow_version):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/__init__.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LooseVersion(pyarrow.__version__) >= LooseVersion(\"2.0.0\")\n",
      "\n",
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/frame.py:62: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) >= LooseVersion(\"0.24\"):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/missing/frame.py:81: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) < LooseVersion(\"1.0\"):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/missing/indexes.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) < LooseVersion(\"1.0\"):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/missing/indexes.py:191: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) < LooseVersion(\"1.0\"):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/missing/series.py:89: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) < LooseVersion(\"1.0\"):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/pandas/groupby.py:50: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) >= LooseVersion(\"1.3.0\"):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/fs/__init__.py:4: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('fs')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/fs/opener/__init__.py:6: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('fs.opener')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('fs')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ads.feature_store.feature_store import FeatureStore\n",
    "from ads.feature_store.feature_group import FeatureGroup\n",
    "from ads.feature_store.model_details import ModelDetails\n",
    "from ads.feature_store.dataset import Dataset\n",
    "from ads.feature_store.common.enums import DatasetIngestionMode\n",
    "\n",
    "\n",
    "from ads.feature_store.feature_group_expectation import ExpectationType\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "from ads.feature_store.feature_store_registrar import FeatureStoreRegistrar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae42d21",
   "metadata": {},
   "source": [
    "<a id=\"data_exploration\"></a>\n",
    "### 3.1. Exploration of data in feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301a3a7",
   "metadata": {},
   "source": [
    "#### 3.1.1 Load Synthetic dataset\n",
    "\n",
    "The `FewShotPromptTemplate` includes:\n",
    "\n",
    "- `prefix` and `suffix`: These likely contain guiding context or instructions.\n",
    "- `examples`: The sample data we defined earlier.\n",
    "- `input_variables`: These variables (\"subject\", \"extra\") are placeholders you can dynamically fill later. For instance, \"subject\" might be filled with \"medical_billing\" to guide the model further.\n",
    "- `example_prompt`: This prompt template is the format we want each example row to take in our prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdf61d",
   "metadata": {},
   "source": [
    "<a id=\"load_featuregroup\"></a>\n",
    "### 3.2. Create feature store logical entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d02a8e",
   "metadata": {},
   "source": [
    "#### 3.2.1 Feature Store\n",
    "Feature store is the top level entity for feature store service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5eeb8a1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "feature_store_resource = (\n",
    "    FeatureStore().\n",
    "    with_description(\"Medical Synthetic Data Feature Store\").\n",
    "    with_compartment_id(compartment_id).\n",
    "    with_display_name(\"Synthetic data details\").\n",
    "    with_offline_config(metastore_id=metastore_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae950e",
   "metadata": {},
   "source": [
    "<a id=\"create_feature_store\"></a>\n",
    "##### Create Feature Store\n",
    "\n",
    "Call the ```.create()``` method of the Feature store instance to create a feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ff457a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: featurestore\n",
       "spec:\n",
       "  compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "  description: Medical Synthetic Data Feature Store\n",
       "  displayName: Synthetic data details\n",
       "  id: 8E61152F4AA860662EB9DAB2C72E80CE\n",
       "  offlineConfig:\n",
       "    metastoreId: ocid1.datacatalogmetastore.oc1.iad.amaaaaaabiudgxya2ipeqjr2m7npnn3kboq4s27erl3ts56wggl6ls6gpn3q\n",
       "type: featureStore"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_store = feature_store_resource.create()\n",
    "feature_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fcc98c",
   "metadata": {},
   "source": [
    "#### 3.2.2 Entity\n",
    "An entity is a logical segregation of feature store entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb8c7240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: entity\n",
       "spec:\n",
       "  compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "  description: description for medical entity details\n",
       "  featureStoreId: 8E61152F4AA860662EB9DAB2C72E80CE\n",
       "  id: 374D7194A3B0114CA621338CE7EC482E\n",
       "  name: Synthetic Medical Entity\n",
       "type: entity"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = feature_store.create_entity(\n",
    "    display_name=\"Synthetic Medical Entity\",\n",
    "    description=\"description for medical entity details\"\n",
    ")\n",
    "entity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac203d",
   "metadata": {},
   "source": [
    "#### 3.2.3 Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06f6f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (0.0.267)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.348-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.0.45-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: openai in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (0.28.0)\n",
      "Collecting openai\n",
      "  Using cached openai-1.3.8-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (1.4.46)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (3.9.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (1.33)\n",
      "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
      "  Downloading langchain_core-0.0.12-py3-none-any.whl.metadata (978 bytes)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (0.0.67)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (1.24.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: sniffio in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.1,>=0.0.12->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_experimental-0.0.45-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached openai-1.3.8-py3-none-any.whl (221 kB)\n",
      "Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging, openai, langchain-core, langchain, langchain_experimental\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.267\n",
      "    Uninstalling langchain-0.0.267:\n",
      "      Successfully uninstalled langchain-0.0.267\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.0.348 langchain-core-0.0.12 langchain_experimental-0.0.45 openai-1.3.8 packaging-23.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain_experimental openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055812fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63be9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(dataframe):\n",
    "    import pandas as pd\n",
    "    import dotenv\n",
    "    from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    from langchain.pydantic_v1 import BaseModel\n",
    "    from langchain_experimental.tabular_synthetic_data.base import SyntheticDataGenerator\n",
    "    from langchain_experimental.tabular_synthetic_data.openai import create_openai_data_generator\n",
    "    from langchain_experimental.tabular_synthetic_data.prompts import SYNTHETIC_FEW_SHOT_SUFFIX, SYNTHETIC_FEW_SHOT_PREFIX\n",
    "\n",
    "    # Set env var OPENAI_API_KEY or load from a .env file:\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    class MedicalBilling(BaseModel):\n",
    "        patient_id: int\n",
    "        patient_name: str\n",
    "        diagnosis_code: str\n",
    "        procedure_code: str\n",
    "        total_charge: float\n",
    "        insurance_claim_amount: float\n",
    "\n",
    "    examples = [\n",
    "        {\n",
    "            \"example\": \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code: \n",
    "            J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis \n",
    "            Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code: \n",
    "            E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
    "\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "        examples=examples,\n",
    "        suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    "        input_variables=[\"subject\", \"extra\"],\n",
    "        example_prompt=OPENAI_TEMPLATE,\n",
    "    )\n",
    "\n",
    "    synthetic_data_generator = create_openai_data_generator(\n",
    "        output_schema=MedicalBilling,\n",
    "        llm=ChatOpenAI(\n",
    "            temperature=1\n",
    "        ),  # You'll need to replace with your actual Language Model instance\n",
    "        prompt=prompt_template,\n",
    "    )\n",
    "\n",
    "    synthetic_results = synthetic_data_generator.generate(\n",
    "        subject=\"medical_billing\",\n",
    "        extra=\"the name must be chosen at random. Make it something you wouldn't normally choose.\",\n",
    "        runs=1,\n",
    "    )\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([result.dict() for result in synthetic_results])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a19a5c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: transformation\n",
       "spec:\n",
       "  compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "  displayName: generate_synthetic_data\n",
       "  featureStoreId: 8E61152F4AA860662EB9DAB2C72E80CE\n",
       "  id: 59FDD727A7234E120F82D81364D81802\n",
       "  sourceCode: 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\n",
       "  transformationMode: pandas\n",
       "type: transformation"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ads.feature_store.transformation import TransformationMode\n",
    "\n",
    "synthetic_transformation = feature_store.create_transformation(\n",
    "    transformation_mode=TransformationMode.PANDAS,\n",
    "    source_code_func=generate_synthetic_data,\n",
    "    display_name=\"generate_synthetic_data\",\n",
    ")\n",
    "\n",
    "synthetic_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6573336",
   "metadata": {},
   "source": [
    "#### 3.2.3 Feature group\n",
    "A feature group is an object that represents a logical group of time-series feature data as it is found in a datasource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372703cc",
   "metadata": {},
   "source": [
    "<a id=\"create_feature_group_flights\"></a>\n",
    "##### Synthetic medical feature Group\n",
    "\n",
    "Create feature group for Synthetic Dataset Feature Group\n",
    "\n",
    "<div>\n",
    "    <img src=\"https://objectstorage.us-ashburn-1.oraclecloud.com/p/hh2NOgFJbVSg4amcLM3G3hkTuHyBD-8aE_iCsuZKEvIav1Wlld-3zfCawG4ycQGN/n/ociodscdev/b/oci-feature-store/o/beta/_images/feature_group_flights.gif\" width=\"700\" height=\"350\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c39260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>diagnosis_code</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>insurance_claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123456</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>J20.9</td>\n",
       "      <td>99203</td>\n",
       "      <td>500.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id patient_name diagnosis_code procedure_code  total_charge  \\\n",
       "0      123456     John Doe          J20.9          99203         500.0   \n",
       "\n",
       "   insurance_claim_amount  \n",
       "0                   350.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_df = pd.DataFrame([{\n",
    "    \"patient_id\": 123456,\n",
    "    \"patient_name\": \"John Doe\",\n",
    "    \"diagnosis_code\": \"J20.9\",\n",
    "    \"procedure_code\": \"99203\",\n",
    "    \"total_charge\": 500.0,\n",
    "    \"insurance_claim_amount\": 350.0,\n",
    "}])\n",
    "empty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c07b8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_values_to_not_be_null\", \"kwargs\": {\"column\": \"diagnosis_code\"}, \"meta\": {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_suite = ExpectationSuite(\n",
    "    expectation_suite_name=\"test_synthetic data\"\n",
    ")\n",
    "expectation_suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"patient_id\"},\n",
    "    )\n",
    ")\n",
    "expectation_suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"patient_name\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "expectation_suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"diagnosis_code\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9c99e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common.oci_client:OCI SDK with feature store support is not installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023/12/11 06:47:03 NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:35: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pyarrow.__version__) < LooseVersion(minimum_pyarrow_version):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group = (\n",
    "    FeatureGroup()\n",
    "    .with_feature_store_id(feature_store.id)\n",
    "    .with_primary_keys([])\n",
    "    .with_name(\"synthetic_data_feature_group\")\n",
    "    .with_entity_id(entity.id)\n",
    "    .with_compartment_id(compartment_id)\n",
    "    .with_schema_details_from_dataframe(empty_df)\n",
    "    .with_transformation_id(synthetic_transformation.id)\n",
    "    .with_expectation_suite(\n",
    "        expectation_suite=expectation_suite,\n",
    "        expectation_type=ExpectationType.STRICT,\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46616314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: FeatureGroup\n",
       "spec:\n",
       "  compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "  entityId: 374D7194A3B0114CA621338CE7EC482E\n",
       "  expectationDetails:\n",
       "    createRuleDetails:\n",
       "    - arguments:\n",
       "        column: patient_id\n",
       "      levelType: ERROR\n",
       "      name: Rule-0\n",
       "      ruleType: expect_column_values_to_not_be_null\n",
       "    - arguments:\n",
       "        column: patient_name\n",
       "      levelType: ERROR\n",
       "      name: Rule-1\n",
       "      ruleType: expect_column_values_to_not_be_null\n",
       "    - arguments:\n",
       "        column: diagnosis_code\n",
       "      levelType: ERROR\n",
       "      name: Rule-2\n",
       "      ruleType: expect_column_values_to_not_be_null\n",
       "    expectationType: STRICT\n",
       "    name: test_synthetic data\n",
       "    validationEngineType: GREAT_EXPECTATIONS\n",
       "  featureStoreId: 8E61152F4AA860662EB9DAB2C72E80CE\n",
       "  id: A9F13BFC6C18A8EE1390B6AAFCAAA932\n",
       "  inputFeatureDetails:\n",
       "  - featureType: LONG\n",
       "    name: patient_id\n",
       "    orderNumber: 1\n",
       "  - featureType: STRING\n",
       "    name: patient_name\n",
       "    orderNumber: 2\n",
       "  - featureType: STRING\n",
       "    name: diagnosis_code\n",
       "    orderNumber: 3\n",
       "  - featureType: STRING\n",
       "    name: procedure_code\n",
       "    orderNumber: 4\n",
       "  - featureType: DOUBLE\n",
       "    name: total_charge\n",
       "    orderNumber: 5\n",
       "  - featureType: DOUBLE\n",
       "    name: insurance_claim_amount\n",
       "    orderNumber: 6\n",
       "  isInferSchema: true\n",
       "  name: synthetic_data_feature_group\n",
       "  primaryKeys:\n",
       "    items: []\n",
       "  statisticsConfig:\n",
       "    isEnabled: true\n",
       "  transformationId: 59FDD727A7234E120F82D81364D81802\n",
       "  transformationParameters: e30=\n",
       "type: featureGroup"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0f5b6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"572pt\" height=\"138pt\"\n",
       " viewBox=\"0.00 0.00 572.00 138.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 134)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-134 568,-134 568,4 -4,4\"/>\n",
       "<!-- 8E61152F4AA860662EB9DAB2C72E80CE -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>8E61152F4AA860662EB9DAB2C72E80CE</title>\n",
       "<path fill=\"#dedede\" stroke=\"#dedede\" d=\"M133,-93C133,-93 12,-93 12,-93 6,-93 0,-87 0,-81 0,-81 0,-49 0,-49 0,-43 6,-37 12,-37 12,-37 133,-37 133,-37 139,-37 145,-43 145,-49 145,-49 145,-81 145,-81 145,-87 139,-93 133,-93\"/>\n",
       "<text text-anchor=\"start\" x=\"12.5\" y=\"-76.2\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"11.00\">Synthetic data details</text>\n",
       "<text text-anchor=\"start\" x=\"48\" y=\"-61.4\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"7.00\">Feature Store</text>\n",
       "<text text-anchor=\"start\" x=\"12.5\" y=\"-47.4\" font-family=\"Courier New\" font-size=\"7.00\">8E61152F4AA860662EB9DAB2C72E80CE</text>\n",
       "</g>\n",
       "<!-- 374D7194A3B0114CA621338CE7EC482E -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>374D7194A3B0114CA621338CE7EC482E</title>\n",
       "<path fill=\"#dedede\" stroke=\"#dedede\" d=\"M328,-130C328,-130 194,-130 194,-130 188,-130 182,-124 182,-118 182,-118 182,-86 182,-86 182,-80 188,-74 194,-74 194,-74 328,-74 328,-74 334,-74 340,-80 340,-86 340,-86 340,-118 340,-118 340,-124 334,-130 328,-130\"/>\n",
       "<text text-anchor=\"start\" x=\"194\" y=\"-113.2\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"11.00\">Synthetic Medical Entity</text>\n",
       "<text text-anchor=\"start\" x=\"250\" y=\"-98.4\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"7.00\">Entity</text>\n",
       "<text text-anchor=\"start\" x=\"200.5\" y=\"-84.4\" font-family=\"Courier New\" font-size=\"7.00\">374D7194A3B0114CA621338CE7EC482E</text>\n",
       "</g>\n",
       "<!-- 8E61152F4AA860662EB9DAB2C72E80CE&#45;&gt;374D7194A3B0114CA621338CE7EC482E -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>8E61152F4AA860662EB9DAB2C72E80CE&#45;&gt;374D7194A3B0114CA621338CE7EC482E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.07,-79.2C153.8,-80.93 162.81,-82.72 171.74,-84.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.3,-87.97 181.79,-86.48 172.67,-81.11 171.3,-87.97\"/>\n",
       "</g>\n",
       "<!-- 59FDD727A7234E120F82D81364D81802 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>59FDD727A7234E120F82D81364D81802</title>\n",
       "<path fill=\"#dedede\" stroke=\"#dedede\" d=\"M329,-56C329,-56 193,-56 193,-56 187,-56 181,-50 181,-44 181,-44 181,-12 181,-12 181,-6 187,0 193,0 193,0 329,0 329,0 335,0 341,-6 341,-12 341,-12 341,-44 341,-44 341,-50 335,-56 329,-56\"/>\n",
       "<text text-anchor=\"start\" x=\"193\" y=\"-39.2\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"11.00\">generate_synthetic_data</text>\n",
       "<text text-anchor=\"start\" x=\"233.5\" y=\"-24.4\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"7.00\">Transformation</text>\n",
       "<text text-anchor=\"start\" x=\"200.5\" y=\"-10.4\" font-family=\"Courier New\" font-size=\"7.00\">59FDD727A7234E120F82D81364D81802</text>\n",
       "</g>\n",
       "<!-- 8E61152F4AA860662EB9DAB2C72E80CE&#45;&gt;59FDD727A7234E120F82D81364D81802 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>8E61152F4AA860662EB9DAB2C72E80CE&#45;&gt;59FDD727A7234E120F82D81364D81802</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.07,-50.8C153.49,-49.13 162.16,-47.41 170.78,-45.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.73,-49.08 180.86,-43.7 170.37,-42.21 171.73,-49.08\"/>\n",
       "</g>\n",
       "<!-- A9F13BFC6C18A8EE1390B6AAFCAAA932 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>A9F13BFC6C18A8EE1390B6AAFCAAA932</title>\n",
       "<path fill=\"#dedede\" stroke=\"#dedede\" d=\"M552,-93C552,-93 389,-93 389,-93 383,-93 377,-87 377,-81 377,-81 377,-49 377,-49 377,-43 383,-37 389,-37 389,-37 552,-37 552,-37 558,-37 564,-43 564,-49 564,-49 564,-81 564,-81 564,-87 558,-93 552,-93\"/>\n",
       "<text text-anchor=\"start\" x=\"389.5\" y=\"-76.2\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"11.00\">synthetic_data_feature_group</text>\n",
       "<text text-anchor=\"start\" x=\"445\" y=\"-61.4\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"7.00\">Feature Group</text>\n",
       "<text text-anchor=\"start\" x=\"410.5\" y=\"-47.4\" font-family=\"Courier New\" font-size=\"7.00\">A9F13BFC6C18A8EE1390B6AAFCAAA932</text>\n",
       "</g>\n",
       "<!-- 374D7194A3B0114CA621338CE7EC482E&#45;&gt;A9F13BFC6C18A8EE1390B6AAFCAAA932 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>374D7194A3B0114CA621338CE7EC482E&#45;&gt;A9F13BFC6C18A8EE1390B6AAFCAAA932</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340.15,-88.06C348.83,-86.52 357.77,-84.92 366.69,-83.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.52,-86.74 376.75,-81.54 366.3,-79.85 367.52,-86.74\"/>\n",
       "</g>\n",
       "<!-- 59FDD727A7234E120F82D81364D81802&#45;&gt;A9F13BFC6C18A8EE1390B6AAFCAAA932 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>59FDD727A7234E120F82D81364D81802&#45;&gt;A9F13BFC6C18A8EE1390B6AAFCAAA932</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M341.04,-42.09C349.44,-43.59 358.06,-45.13 366.68,-46.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.32,-50.16 376.78,-48.47 367.55,-43.26 366.32,-50.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f0095584880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef0b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = af9e5f7e-4a9d-4990-9f39-07619a03b6ef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:great_expectations.validator.validator:\t3 expectation(s) included in expectation_suite.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da2c0c96a849c0b18ef31b1b0c7839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ads.feature_store.common.utils.utility:Validation Summary \n",
      "╒════════════════════╤══════════════════════════╤═══════════════════════════╤═════════════════════════════╤═══════════════════╤═══════════════════════╕\n",
      "│  expectation_type  │  evaluated_expectations  │  successful_expectations  │  unsuccessful_expectations  │  success_percent  │   ingestion_status    │\n",
      "╞════════════════════╪══════════════════════════╪═══════════════════════════╪═════════════════════════════╪═══════════════════╪═══════════════════════╡\n",
      "│       STRICT       │            3             │             3             │              0              │        100        │ Ingestion in progress │\n",
      "╘════════════════════╧══════════════════════════╧═══════════════════════════╧═════════════════════════════╧═══════════════════╧═══════════════════════╛\n",
      "INFO:ads.feature_store.common.utils.utility:Validations Rules Summary \n",
      "╒═════════════════════════════════════╤══════════════════════════════╤══════════╕\n",
      "│              rule_type              │          arguments           │  status  │\n",
      "╞═════════════════════════════════════╪══════════════════════════════╪══════════╡\n",
      "│ expect_column_values_to_not_be_null │   {'column': 'patient_id'}   │   True   │\n",
      "├─────────────────────────────────────┼──────────────────────────────┼──────────┤\n",
      "│ expect_column_values_to_not_be_null │  {'column': 'patient_name'}  │   True   │\n",
      "├─────────────────────────────────────┼──────────────────────────────┼──────────┤\n",
      "│ expect_column_values_to_not_be_null │ {'column': 'diagnosis_code'} │   True   │\n",
      "╘═════════════════════════════════════╧══════════════════════════════╧══════════╛\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/langchain_core/prompts/prompt.py:200: DeprecationWarning: `input_variables' is deprecated and ignored.\n",
      "  warnings.warn(\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:35: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pyarrow.__version__) < LooseVersion(minimum_pyarrow_version):\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/mlm_insights/core/metrics/drift_metrics/chi_square.py:239: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\"Reference profile is empty\")\n",
      "\n",
      "INFO:ads.feature_store.common.utils.utility:Ingestion Summary \n",
      "╒══════════════════════════════════╤═══════════════╤════════════════════╤═════════════════╕\n",
      "│            entity_id             │  entity_type  │  ingestion_status  │  error_details  │\n",
      "╞══════════════════════════════════╪═══════════════╪════════════════════╪═════════════════╡\n",
      "│ A9F13BFC6C18A8EE1390B6AAFCAAA932 │ FEATURE_GROUP │     Succeeded      │      None       │\n",
      "╘══════════════════════════════════╧═══════════════╧════════════════════╧═════════════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/mlm_insights/core/sfcs/descriptive_statistics_sfc.py:80: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  self.central_moments = [moment(column, moment=i) for i in range(MAXIMUM_MOMENT_ORDER + 1)]\n",
      "/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/mlm_insights/core/sfcs/descriptive_statistics_sfc.py:80: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  self.central_moments = [moment(column, moment=i) for i in range(MAXIMUM_MOMENT_ORDER + 1)]\n",
      "/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/mlm_insights/core/sfcs/descriptive_statistics_sfc.py:80: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  self.central_moments = [moment(column, moment=i) for i in range(MAXIMUM_MOMENT_ORDER + 1)]\n",
      "/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pandas/core/nanops.py:1609: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return np.cov(a, b, ddof=ddof)[0, 1]\n",
      "/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/numpy/lib/function_base.py:2705: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.materialise(empty_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdfc34",
   "metadata": {},
   "source": [
    "<a id=\"explore_featuregroup\"></a>\n",
    "### 3.3. Explore feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58474b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|userId|userName|           operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      0|2023-12-11 06:47:36|  null|    null|CREATE OR REPLACE...|{isManaged -> tru...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.2....|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.history().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959b4a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------------+--------------+------------+----------------------+\n",
      "|patient_id|   patient_name|diagnosis_code|procedure_code|total_charge|insurance_claim_amount|\n",
      "+----------+---------------+--------------+--------------+------------+----------------------+\n",
      "|    987654|Michael Johnson|         A09.9|         99205|       800.0|                 600.0|\n",
      "+----------+---------------+--------------+--------------+------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.as_of(version_number=0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac8def07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_id</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_name</td>\n",
       "      <td>STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis_code</td>\n",
       "      <td>STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>procedure_code</td>\n",
       "      <td>STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_charge</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insurance_claim_amount</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name    type\n",
       "0              patient_id    LONG\n",
       "1            patient_name  STRING\n",
       "2          diagnosis_code  STRING\n",
       "3          procedure_code  STRING\n",
       "4            total_charge  DOUBLE\n",
       "5  insurance_claim_amount  DOUBLE"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.get_features_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80cf1d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectation_config.expectation_type</th>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectation_config.kwargs.column</th>\n",
       "      <td>patient_id</td>\n",
       "      <td>patient_name</td>\n",
       "      <td>diagnosis_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectation_config.kwargs.batch_id</th>\n",
       "      <td>c61d30e4082fb44d2a5b776e4132c6cd</td>\n",
       "      <td>c61d30e4082fb44d2a5b776e4132c6cd</td>\n",
       "      <td>c61d30e4082fb44d2a5b776e4132c6cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.element_count</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.unexpected_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.unexpected_percent</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.partial_unexpected_list</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exception_info.raised_exception</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exception_info.exception_traceback</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exception_info.exception_message</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0  \\\n",
       "success                                                             True   \n",
       "expectation_config.expectation_type  expect_column_values_to_not_be_null   \n",
       "expectation_config.kwargs.column                              patient_id   \n",
       "expectation_config.kwargs.batch_id      c61d30e4082fb44d2a5b776e4132c6cd   \n",
       "result.element_count                                                   1   \n",
       "result.unexpected_count                                                0   \n",
       "result.unexpected_percent                                            0.0   \n",
       "result.partial_unexpected_list                                        []   \n",
       "exception_info.raised_exception                                    False   \n",
       "exception_info.exception_traceback                                  None   \n",
       "exception_info.exception_message                                    None   \n",
       "\n",
       "                                                                       1  \\\n",
       "success                                                             True   \n",
       "expectation_config.expectation_type  expect_column_values_to_not_be_null   \n",
       "expectation_config.kwargs.column                            patient_name   \n",
       "expectation_config.kwargs.batch_id      c61d30e4082fb44d2a5b776e4132c6cd   \n",
       "result.element_count                                                   1   \n",
       "result.unexpected_count                                                0   \n",
       "result.unexpected_percent                                            0.0   \n",
       "result.partial_unexpected_list                                        []   \n",
       "exception_info.raised_exception                                    False   \n",
       "exception_info.exception_traceback                                  None   \n",
       "exception_info.exception_message                                    None   \n",
       "\n",
       "                                                                       2  \n",
       "success                                                             True  \n",
       "expectation_config.expectation_type  expect_column_values_to_not_be_null  \n",
       "expectation_config.kwargs.column                          diagnosis_code  \n",
       "expectation_config.kwargs.batch_id      c61d30e4082fb44d2a5b776e4132c6cd  \n",
       "result.element_count                                                   1  \n",
       "result.unexpected_count                                                0  \n",
       "result.unexpected_percent                                            0.0  \n",
       "result.partial_unexpected_list                                        []  \n",
       "exception_info.raised_exception                                    False  \n",
       "exception_info.exception_traceback                                  None  \n",
       "exception_info.exception_message                                    None  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.get_validation_output().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f634e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------------+--------------+------------+----------------------+\n",
      "|patient_id|   patient_name|diagnosis_code|procedure_code|total_charge|insurance_claim_amount|\n",
      "+----------+---------------+--------------+--------------+------------+----------------------+\n",
      "|    987654|Michael Johnson|         A09.9|         99205|       800.0|                 600.0|\n",
      "+----------+---------------+--------------+--------------+------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.select().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54426389",
   "metadata": {},
   "source": [
    "<a id=\"select_subset_featuregroup\"></a>\n",
    "### 3.4. Select subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5809ea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|patient_id|   patient_name|\n",
      "+----------+---------------+\n",
      "|    987654|Michael Johnson|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.select(['patient_id', 'patient_name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48292c35",
   "metadata": {},
   "source": [
    "<a id=\"filter_featuregroup\"></a>\n",
    "### 3.5. Filter feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9386b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+--------------+------------+----------------------+\n",
      "|patient_id|patient_name|diagnosis_code|procedure_code|total_charge|insurance_claim_amount|\n",
      "+----------+------------+--------------+--------------+------------+----------------------+\n",
      "+----------+------------+--------------+--------------+------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_embedding_feature_group.filter(synthetic_data_embedding_feature_group.patient_id == \"123456\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "972a5db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:35: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "\n",
      "WARNING:py.warnings:/home/datascience/conda/fspyspark32_p38_cpu_v2/lib/python3.8/site-packages/pyspark/sql/pandas/utils.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pyarrow.__version__) < LooseVersion(minimum_pyarrow_version):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>diagnosis_code</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>insurance_claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987654</td>\n",
       "      <td>Michael Johnson</td>\n",
       "      <td>A09.9</td>\n",
       "      <td>99205</td>\n",
       "      <td>800.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id     patient_name diagnosis_code procedure_code  total_charge  \\\n",
       "0      987654  Michael Johnson          A09.9          99205         800.0   \n",
       "\n",
       "   insurance_claim_amount  \n",
       "0                   600.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranining_df = synthetic_data_embedding_feature_group.select().read().toPandas()\n",
    "tranining_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95257602",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf1413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64849e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fspyspark32_p38_cpu_v2]",
   "language": "python",
   "name": "conda-env-fspyspark32_p38_cpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
