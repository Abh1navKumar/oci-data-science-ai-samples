{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere Embedding Models for Semantic Search in OCI OpenSearch\n",
    "In this tutorial, we will walk through the steps to conduct a semantic search using the Cohere embedding model with OCI Search.\n",
    "\n",
    "### Prerequesites\n",
    "- You have a Running Instance of OCI Search\n",
    "\n",
    "To check how to spin up an instance of OCI search, see [Search and visualize data using OCI Search Service with OpenSearch](https://docs.oracle.com/en/learn/oci-opensearch/index.html#introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade oci langchain opensearch-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Split your Documents Into Chunks\n",
    "Let's say you're looking to create a search engine that enables users to search through documentation stored as markdown files. Actually, it does not matter what file format your documentation are in as Langchain offers support for various types of document loaders. In this tutorial, we will just use markdown file as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "with open(\"your_markdown_file.md\") as f:\n",
    "    report = f.read()\n",
    "    \n",
    "    \n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"head 1\"),\n",
    "    (\"##\", \"head 2\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(report)\n",
    "texts = [text.page_content for text in md_header_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Embed your Documents\n",
    "\n",
    "You can use oracle-ads to access the GenerativeAI embedding models. The embedding models returns embedding vectors of length 1024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "from ads.llm import GenerativeAIEmbeddings\n",
    " \n",
    "ads.set_auth(auth=\"resource_principal\")\n",
    " \n",
    "oci_embedings = GenerativeAIEmbeddings(\n",
    "    compartment_id=\"ocid1.compartment.oc1.######\",\n",
    "    client_kwargs=dict(service_endpoint=\"generativeai_service_endpoint\")\n",
    ")\n",
    "embeddings = oci_embedings.embed_document(texts=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create an Index for your Documents\n",
    "\n",
    "First connect to your OCI search cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the opensearch cluster.\n",
    "from opensearchpy import OpenSearch\n",
    " \n",
    "# Create a connection to your OpenSearch cluster\n",
    "es = OpenSearch(\n",
    "    ['https://####'],  # Replace with your OpenSearch endpoint URL\n",
    "    http_auth=('username', 'password'),  # Replace with your credentials\n",
    "    verify_certs=False,  # Set to True if you want to verify SSL certificates\n",
    "    timeout=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you must create a k-NN index and set the index.knn parameter to true. This settings tells the plugin to generate native library indexes specifically tailored for k-NN searches. \n",
    "\n",
    "Next, you must add one or more fields of the knn_vector data type. This example creates an index with one knn_vector and one text. THe knn_vector uses lucene fields.\n",
    "\n",
    "See [documentation](https://opensearch.org/docs/2.7/search-plugins/knn/knn-index#method-definitions) for more details on parameters' definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"arxiv-cosine-1\"\n",
    "VECTOR_1_NAME = \"embedding_vector\"\n",
    "VECTOR_2_NAME = \"text\"\n",
    " \n",
    "body = {\n",
    "    \"settings\": {\"index\": {\"knn\": \"true\", \"knn.algo_param.ef_search\": 100}}, # Index setting: https://opensearch.org/docs/2.11/search-plugins/knn/knn-index\n",
    "    \"mappings\": { # Explicit mapping: https://opensearch.org/docs/2.11/field-types/index/#explicit-mapping\n",
    "        \"properties\": {\n",
    "            VECTOR_1_NAME: {\n",
    "                \"type\": \"knn_vector\", # Supported field types: https://opensearch.org/docs/2.11/field-types/supported-field-types/index/\n",
    "                \"dimension\": 1024,\n",
    "                \"method\": { # Method definition: https://opensearch.org/docs/2.11/search-plugins/knn/knn-index#method-definitions\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"cosinesimil\",\n",
    "                    \"engine\": \"lucene\",\n",
    "                    \"parameters\": {\"ef_construction\": 128, \"m\": 24},\n",
    "                },\n",
    "            },\n",
    "            VECTOR_2_NAME: {\n",
    "                 \"type\": \"text\"\n",
    "               },\n",
    "        }\n",
    "    },\n",
    "}\n",
    "response = es.indices.create(INDEX_NAME, body=body)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Insert the Embedding Vectors for your Documents\n",
    "Now let's populate the index using the embedding vectors calculated from your documents using Cohere Embedding Models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"arxiv-cosine-1\"\n",
    "i = 0\n",
    "# insert each row one-at-a-time to the document index\n",
    "for text, embed in zip(texts, embeddings):\n",
    " \n",
    "    try:\n",
    "         \n",
    "        body = {\n",
    "            VECTOR_1_NAME: embed,\n",
    "            VECTOR_2_NAME: text,\n",
    "        }\n",
    "        response = es.index(index=INDEX_NAME, body=body)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR]: {e}\")\n",
    "        continue\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A new query coming in, first calcualte the embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = oci_embedings.embed_query(texts=\"how to build the html documentation\")\n",
    "query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\"knn\": {VECTOR_1_NAME: {\"vector\": query_vector, \"k\": 2}}},\n",
    "}\n",
    " \n",
    "response = es.search(body=query, index=INDEX_NAME)  # the same as before\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run it in terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"arxiv-cosine-1\"\n",
    "with open('my_vector.txt', 'w') as file:\n",
    "    # Convert the list elements to strings and write them to the file\n",
    "    for item in query_vector:\n",
    "        file.write(str(item) + ',\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "export vector_data=$(<my_vector.txt)\n",
    " \n",
    "# Construct the CURL command with the vector data\n",
    "curl -X GET \"https://private_endpoint/arxiv-cosine-1/_search\" --insecure  -k -u username:password  -H \"Content-Type: application/json\" -d '{\n",
    "  \"size\": 2,\n",
    "  \"query\": {\n",
    "    \"knn\": {\n",
    "      \"embedding_vector\": {\n",
    "        \"vector\": '\"$vector_data\"',\n",
    "        \"k\": 2\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
