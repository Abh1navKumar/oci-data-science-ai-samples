2023-12-21 16:53:52,481 - uvicorn.error - INFO - Started server process [26]
2023-12-21 16:53:52,481 - uvicorn.error - INFO - Waiting for application startup.
2023-12-21 16:53:52,482 - uvicorn.error - INFO - Application startup complete.
2023-12-21 16:53:52,482 - uvicorn.error - INFO - Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
2023-12-21 16:54:15,430 - uvicorn.access - INFO - 172.17.0.1:56548 - "POST /generate HTTP/1.1" 404
2023-12-21 16:54:15,430 - uvicorn.access - INFO - 172.17.0.1:56548 - "POST /generate HTTP/1.1" 404
2023-12-21 16:54:26,258 - asyncio - ERROR - Exception in callback functools.partial(<function _raise_exception_on_finish at 0x7f2869be41f0>, request_tracker=<vllm.engine.async_llm_engine.RequestTracker object at 0x7f285c151640>)
handle: <Handle functools.partial(<function _raise_exception_on_finish at 0x7f2869be41f0>, request_tracker=<vllm.engine.async_llm_engine.RequestTracker object at 0x7f285c151640>)>
Traceback (most recent call last):
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 28, in _raise_exception_on_finish
    task.result()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 351, in run_engine_loop
    has_requests_in_progress = await self.engine_step()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 322, in engine_step
    self.engine.add_request(**new_request)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 264, in add_request
    assert prompt is not None
AssertionError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 37, in _raise_exception_on_finish
    raise exc
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 32, in _raise_exception_on_finish
    raise AsyncEngineDeadError(
vllm.engine.async_llm_engine.AsyncEngineDeadError: Task finished unexpectedly. This should never happen! Please open an issue on Github. See stack trace above for the actual cause.
2023-12-21 16:54:26,259 - uvicorn.access - INFO - 172.17.0.1:39442 - "POST /predict HTTP/1.1" 500
2023-12-21 16:54:26,259 - uvicorn.access - INFO - 172.17.0.1:39442 - "POST /predict HTTP/1.1" 500
2023-12-21 16:54:26,259 - uvicorn.error - ERROR - Exception in ASGI application
Traceback (most recent call last):
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 28, in _raise_exception_on_finish
    task.result()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 351, in run_engine_loop
    has_requests_in_progress = await self.engine_step()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 322, in engine_step
    self.engine.add_request(**new_request)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 264, in add_request
    assert prompt is not None
AssertionError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/uvicorn/protocols/http/httptools_impl.py", line 426, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/fastapi/applications.py", line 1106, in __call__
    await super().__call__(scope, receive, send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/applications.py", line 122, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/middleware/errors.py", line 184, in __call__
    raise exc
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/middleware/errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/middleware/exceptions.py", line 79, in __call__
    raise exc
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/middleware/exceptions.py", line 68, in __call__
    await self.app(scope, receive, sender)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/fastapi/middleware/asyncexitstack.py", line 20, in __call__
    raise e
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/fastapi/middleware/asyncexitstack.py", line 17, in __call__
    await self.app(scope, receive, send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/routing.py", line 718, in __call__
    await route.handle(scope, receive, send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/routing.py", line 276, in handle
    await self.app(scope, receive, send)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/starlette/routing.py", line 66, in app
    response = await func(request)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/fastapi/routing.py", line 274, in app
    raw_response = await run_endpoint_function(
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/opt/vllm/vllm-api-server.py", line 78, in generate
    async for request_output in results_generator:
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 436, in generate
    raise e
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 430, in generate
    async for request_output in stream:
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 70, in __anext__
    raise result
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 37, in _raise_exception_on_finish
    raise exc
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 32, in _raise_exception_on_finish
    raise AsyncEngineDeadError(
vllm.engine.async_llm_engine.AsyncEngineDeadError: Task finished unexpectedly. This should never happen! Please open an issue on Github. See stack trace above for the actual cause.
2023-12-21 16:54:48,504 - asyncio - ERROR - Future exception was never retrieved
future: <Future finished exception=AssertionError()>
Traceback (most recent call last):
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 28, in _raise_exception_on_finish
    task.result()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 351, in run_engine_loop
    has_requests_in_progress = await self.engine_step()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 322, in engine_step
    self.engine.add_request(**new_request)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 264, in add_request
    assert prompt is not None
AssertionError
2023-12-21 16:54:48,505 - asyncio - ERROR - Exception in callback functools.partial(<function _raise_exception_on_finish at 0x7f2869be41f0>, request_tracker=<vllm.engine.async_llm_engine.RequestTracker object at 0x7f285c151640>)
handle: <Handle functools.partial(<function _raise_exception_on_finish at 0x7f2869be41f0>, request_tracker=<vllm.engine.async_llm_engine.RequestTracker object at 0x7f285c151640>)>
Traceback (most recent call last):
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 28, in _raise_exception_on_finish
    task.result()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 351, in run_engine_loop
    has_requests_in_progress = await self.engine_step()
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 322, in engine_step
    self.engine.add_request(**new_request)
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 264, in add_request
    assert prompt is not None
AssertionError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 37, in _raise_exception_on_finish
    raise exc
  File "/miniconda/envs/vllm/lib/python3.9/site-packages/vllm/engine/async_llm_engine.py", line 32, in _raise_exception_on_finish
    raise AsyncEngineDeadError(
vllm.engine.async_llm_engine.AsyncEngineDeadError: Task finished unexpectedly. This should never happen! Please open an issue on Github. See stack trace above for the actual cause.
2023-12-21 16:54:48,505 - uvicorn.access - INFO - 172.17.0.1:54936 - "POST /predict HTTP/1.1" 500
2023-12-21 16:54:48,505 - uvicorn.access - INFO - 172.17.0.1:54936 - "POST /predict HTTP/1.1" 500
